{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP5 (Perceptron multicouche avec jeux de donnees .csv)\n",
    "##    GROUPE 3 CONSTITUE DE :\n",
    "##        - LEPAFO MOFFO Baurel               21S2782\n",
    "##        - MANFOUO SELATSA Ridano            16U2848\n",
    "##        - TEINGA KAMGUEN Emmanuel Rufin     21S2822\n",
    "##        - MEBODO ONOMO JUSTIN JORDAN        19M2217\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pour resoudre un probleme avec les reseaux de neuronnes ils nous faut :\n",
    "##  - faire une enquete sur quel architecture des reseaux de neuronnes est le plus convenable  pour le probleme cite\n",
    "##  - Definir l'architechture du reseau de neuronne au travers du langage ou de la librairie choisie\n",
    "##  - Convertir les donnees dans un bon format(one hot encoding et word2vec encoding) et les diviser en lot/groupe\n",
    "##  - faire un des donnees accordees a nos besoins\n",
    "##  - Augmenter les donnees pour augmenter la taille du jeux d'entrainement et d'avoir de meilleur rendu d'entrainement\n",
    "##  - alimenter les batch(groupes) au reseau de neuronnes\n",
    "##  - Entrainer et controler les changements dans l'ensemble d'entrainement et de validation\n",
    "##  - Pour finir tester le modele et le sauvegarder  pour une future utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dans notre devoir nous travaillons sur l'identification des chiffres  (Indentify Digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program_Files_Disque_E\\Anaconda\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['test', 'seed']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pillow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-d82ae50be691>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpillow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pillow'"
     ]
    }
   ],
   "source": [
    "## ici on commence par importer les library necessaire\n",
    "\n",
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pour arreter d'avoir a chaque redemarrage de cette cellule du notebook d'avoir differentes valeurs\n",
    "\n",
    "seed=128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cette etape consiste a garder les chemin d'acces aus differents dossiers\n",
    "root_dir =os.path.abspath('./')\n",
    "data_dir = os.path.join(root_dir,'data')\n",
    "## pour regarder l'existence , des differents dossiers, \n",
    "## on fait:\n",
    "os.path.exists(root_dir)\n",
    "os.path.exists(data_dir)\n",
    "## pour savoir si les chemeins existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## chargeons les donnees:\n",
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir,'Test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir,'sample_submission.csv'))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cle de notre jeux de test\n",
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## regardons a quoi ressemble nos donnees\n",
    "\n",
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir,'Images','train',img_name)\n",
    "\n",
    "img = imageio.imread(filepath,as_gray=True)\n",
    "pylab.imshow(img,cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  36., 163.,\n",
       "        254., 254., 144.,  58.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  92., 247., 242.,\n",
       "        187., 187., 225., 233.,  60.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 137., 243., 249.,  79.,\n",
       "          0.,   0.,  40., 223., 193.,   4.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 151., 192.,  19.,   0.,\n",
       "          0.,   0.,   0., 120., 253.,  69.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  67., 253., 121.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  67., 253., 121.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   2., 171., 253., 121.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  34., 253., 253., 121.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  68., 253., 253.,  39.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0., 144., 253., 210.,   6.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  81., 255., 254.,  88.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  11.,  77., 194., 247.,  91.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,  17., 202., 198.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 133., 251.,  52.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 205., 253.,  55.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 118., 251., 210.,  12.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,  16., 151., 250., 252., 141.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7., 155.,\n",
       "         73., 141., 168., 253., 253., 163.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   8., 189.,\n",
       "        253., 253., 254., 253., 189.,  36.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,\n",
       "        147., 253., 192., 143.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-c96699c4ada4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m255.0\u001b[0m \u001b[1;31m## on divise pour avoir les donnees facile a calculer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mE:\\Program_Files_Disque_E\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m     \u001b[0mexpanded_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program_Files_Disque_E\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m     \u001b[0mexpanded_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## enregistrement de nos donnees dans un tableau numpy\n",
    "\n",
    "temp = []\n",
    "\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join(data_dir,'Images','train', img_name)\n",
    "    img = imageio.imread(image_path,as_gray=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "\n",
    "print(temp)\n",
    "train_x=np.stack(temp)\n",
    "print(train_x)\n",
    "train_x /= 255.0 ## on divise pour avoir les donnees facile a calculer\n",
    "\n",
    "train_x = train_x.reshape(-1,784).astype('float32')\n",
    "\n",
    "\n",
    "temp = []\n",
    "\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join(data_dir,'Images','test',img_name)\n",
    "    img= imageio.imread(image_path)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "\n",
    "test_x = np.stack(temp)\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1,  784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divison le jeux de donnee en ensemble d'entrainement et de vaidation\n",
    "## 70% , 30%\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x,val_x =train_x[:split_size],train_x[split_size:]\n",
    "train_y,val_y =train_y[:split_size],train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voici comment on crée le modèle\n",
    "\n",
    "input_num_units = 784\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Importation des modules keras pour creer notre modele\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Creation du modele\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(input_num_units, activation = 'relu'), \n",
    "    Dense(hidden_num_units, activation='relu'),\n",
    "    # On utilise une d'activation ReLu pour les couches cachees et celle d'entrees\n",
    "    Dense(output_num_units, activation = 'softmax')\n",
    "    # On utilise la fonction d'activation softmax pour la couche de sortie\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du model avec les attributs necessaires\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 4s 13ms/step - loss: 0.2981 - accuracy: 0.9129 - val_loss: 0.1612 - val_accuracy: 0.9522\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 0.1143 - accuracy: 0.9661 - val_loss: 0.1129 - val_accuracy: 0.9659\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0947 - val_accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.0964 - val_accuracy: 0.9716\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0924 - val_accuracy: 0.9709\n"
     ]
    }
   ],
   "source": [
    "## entrainement du modele\n",
    "# ici nb_epochs est remplace par epochs\n",
    "trained_model = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passons a l'evaluation de notre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(test_x),axis=1)## on predit les classe de notre jeux de test\n",
    "img_name = rng.choice(test.filename) ## on fait un choix aleatoire pour notre jeux de text par nom de fichier\n",
    "filepath = os.path.join(data_dir, 'Images', 'test', img_name)\n",
    "img = imread(filepath)\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "print(\"Prediction is: \", pred[test_index])\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pour voir si notre modele predit bien nous allons utiliser notre jeux de soumission\n",
    "\n",
    "sample_submission.filename = test.filename;\n",
    "sample_submission.label = pred\n",
    "sample_submission.to_csv(os.path.join('sample_submission.csv'),index='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Voyons maintenant les hyperparametre a avoir pour un reseau de neurones\n",
    "## nous avons entre autre: Le type d'architechture,le nombre de couches, Nombre de neuronnes,le pas,type d'optimisation,Drop out rate, Les poids\n",
    "\n",
    "## importation des bibliotheques\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## suppression d'aleatoire\n",
    "seed =128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ici Nous augmentons un peu le nombre d'unite de couche cachee\n",
    "input_num_units = 784\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Creation du modele\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(input_num_units, activation = 'relu'),\n",
    "    Dense(hidden_num_units, activation='relu'),\n",
    "    # On utilise une d'activation ReLu pour les couches cachees et celle d'entrees\n",
    "    Dense(output_num_units, activation = 'softmax')\n",
    "    # On utilise la fonction d'activation softmax pour la couche de sortie\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 6s 19ms/step - loss: 0.2526 - accuracy: 0.9263 - val_loss: 0.1397 - val_accuracy: 0.9576\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0905 - accuracy: 0.9716 - val_loss: 0.1206 - val_accuracy: 0.9649\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 5s 18ms/step - loss: 0.0564 - accuracy: 0.9820 - val_loss: 0.0874 - val_accuracy: 0.9726\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0912 - val_accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 5s 19ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0996 - val_accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "## compilation du modele sachant le nombre d'unite de couche cachee modifiees\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_500 = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ici haut on remarque que notre loss function a une valeur beaucoup plus decroissante que dans le cas precedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ajoutons d'autres couches cachees de taille 50,50\n",
    "\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# Creation du modele\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(input_num_units, activation = 'relu'),\n",
    "    Dense(hidden1_num_units, activation='relu'),\n",
    "    Dense(hidden2_num_units, activation='relu'),\n",
    "    Dense(hidden3_num_units, activation='relu'),\n",
    "    Dense(hidden4_num_units, activation='relu'),\n",
    "    Dense(hidden4_num_units, activation='relu'),\n",
    "    # On utilise une d'activation ReLu pour les couches cachees et celle d'entrees\n",
    "    Dense(output_num_units, activation = 'softmax')\n",
    "    # On utilise la fonction d'activation softmax pour la couche de sortie\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.4242 - accuracy: 0.8699 - val_loss: 0.1971 - val_accuracy: 0.9454\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 3s 12ms/step - loss: 0.1396 - accuracy: 0.9590 - val_loss: 0.1329 - val_accuracy: 0.9609\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 4s 13ms/step - loss: 0.0921 - accuracy: 0.9720 - val_loss: 0.1227 - val_accuracy: 0.9621\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 3s 13ms/step - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.1152 - val_accuracy: 0.9671\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 3s 13ms/step - loss: 0.0502 - accuracy: 0.9841 - val_loss: 0.1154 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "## compilation du modele sachant le nombre de couches cachee modifiees\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## l'entrainement fonctionne mais nous n'avons pas le resultat voulu ajoutons ici bas le dropout rate\n",
    "\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " \n",
    " Dense(hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden2_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden3_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden4_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden5_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    "    \n",
    " Dense(output_num_units,activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 [==============================] - 5s 16ms/step - loss: 0.9834 - accuracy: 0.6610 - val_loss: 0.2753 - val_accuracy: 0.9273\n",
      "Epoch 2/5\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.3439 - accuracy: 0.9130 - val_loss: 0.2095 - val_accuracy: 0.9475\n",
      "Epoch 3/5\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2373 - accuracy: 0.9423 - val_loss: 0.1667 - val_accuracy: 0.9594\n",
      "Epoch 4/5\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.1855 - accuracy: 0.9552 - val_loss: 0.1502 - val_accuracy: 0.9652\n",
      "Epoch 5/5\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1557 - accuracy: 0.9620 - val_loss: 0.1495 - val_accuracy: 0.9665\n"
     ]
    }
   ],
   "source": [
    "## regardons le taux de succes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d_with_dropout = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bon ici nous voyons que nous n'obtenons pas le resultat voulu augmentons un peu la nombre d'epochs a 50\n",
    "\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " \n",
    " Dense(hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden2_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden3_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden4_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden5_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    "    \n",
    " Dense(output_num_units,activation='softmax'),\n",
    " ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "268/268 [==============================] - 5s 15ms/step - loss: 1.1225 - accuracy: 0.6045 - val_loss: 0.3783 - val_accuracy: 0.8659\n",
      "Epoch 2/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.3872 - accuracy: 0.8922 - val_loss: 0.2053 - val_accuracy: 0.9459\n",
      "Epoch 3/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2560 - accuracy: 0.9352 - val_loss: 0.1656 - val_accuracy: 0.9588\n",
      "Epoch 4/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.2045 - accuracy: 0.9493 - val_loss: 0.1624 - val_accuracy: 0.9596\n",
      "Epoch 5/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.1643 - accuracy: 0.9610 - val_loss: 0.1404 - val_accuracy: 0.9646\n",
      "Epoch 6/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.1415 - accuracy: 0.9669 - val_loss: 0.1304 - val_accuracy: 0.9689\n",
      "Epoch 7/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1194 - accuracy: 0.9715 - val_loss: 0.1386 - val_accuracy: 0.9681\n",
      "Epoch 8/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.1071 - accuracy: 0.9739 - val_loss: 0.1283 - val_accuracy: 0.9705\n",
      "Epoch 9/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0983 - accuracy: 0.9753 - val_loss: 0.1472 - val_accuracy: 0.9704\n",
      "Epoch 10/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0900 - accuracy: 0.9783 - val_loss: 0.1298 - val_accuracy: 0.9708\n",
      "Epoch 11/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0885 - accuracy: 0.9790 - val_loss: 0.1310 - val_accuracy: 0.9725\n",
      "Epoch 12/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0773 - accuracy: 0.9817 - val_loss: 0.1276 - val_accuracy: 0.9728\n",
      "Epoch 13/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0668 - accuracy: 0.9839 - val_loss: 0.1355 - val_accuracy: 0.9735\n",
      "Epoch 14/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0735 - accuracy: 0.9824 - val_loss: 0.1266 - val_accuracy: 0.9747\n",
      "Epoch 15/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0674 - accuracy: 0.9843 - val_loss: 0.1274 - val_accuracy: 0.9754\n",
      "Epoch 16/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0558 - accuracy: 0.9867 - val_loss: 0.1347 - val_accuracy: 0.9763\n",
      "Epoch 17/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0593 - accuracy: 0.9867 - val_loss: 0.1171 - val_accuracy: 0.9753\n",
      "Epoch 18/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0519 - accuracy: 0.9867 - val_loss: 0.1465 - val_accuracy: 0.9746\n",
      "Epoch 19/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0537 - accuracy: 0.9868 - val_loss: 0.1358 - val_accuracy: 0.9759\n",
      "Epoch 20/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0517 - accuracy: 0.9873 - val_loss: 0.1290 - val_accuracy: 0.9769\n",
      "Epoch 21/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0484 - accuracy: 0.9894 - val_loss: 0.1433 - val_accuracy: 0.9727\n",
      "Epoch 22/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0483 - accuracy: 0.9882 - val_loss: 0.1294 - val_accuracy: 0.9753\n",
      "Epoch 23/50\n",
      "268/268 [==============================] - 4s 14ms/step - loss: 0.0430 - accuracy: 0.9899 - val_loss: 0.1448 - val_accuracy: 0.9763\n",
      "Epoch 24/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 0.1483 - val_accuracy: 0.9731\n",
      "Epoch 25/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0384 - accuracy: 0.9908 - val_loss: 0.1441 - val_accuracy: 0.9763\n",
      "Epoch 26/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0422 - accuracy: 0.9893 - val_loss: 0.1459 - val_accuracy: 0.9754\n",
      "Epoch 27/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0440 - accuracy: 0.9902 - val_loss: 0.1586 - val_accuracy: 0.9736\n",
      "Epoch 28/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0436 - accuracy: 0.9899 - val_loss: 0.1421 - val_accuracy: 0.9762\n",
      "Epoch 29/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0331 - accuracy: 0.9914 - val_loss: 0.1448 - val_accuracy: 0.9755\n",
      "Epoch 30/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0306 - accuracy: 0.9929 - val_loss: 0.1542 - val_accuracy: 0.9752\n",
      "Epoch 31/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0326 - accuracy: 0.9927 - val_loss: 0.1520 - val_accuracy: 0.9763\n",
      "Epoch 32/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 0.1696 - val_accuracy: 0.9737\n",
      "Epoch 33/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0333 - accuracy: 0.9925 - val_loss: 0.1498 - val_accuracy: 0.9759\n",
      "Epoch 34/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0340 - accuracy: 0.9924 - val_loss: 0.1555 - val_accuracy: 0.9754\n",
      "Epoch 35/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0313 - accuracy: 0.9931 - val_loss: 0.1538 - val_accuracy: 0.9757\n",
      "Epoch 36/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0279 - accuracy: 0.9929 - val_loss: 0.1574 - val_accuracy: 0.9758\n",
      "Epoch 37/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0337 - accuracy: 0.9926 - val_loss: 0.1546 - val_accuracy: 0.9773\n",
      "Epoch 38/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0238 - accuracy: 0.9945 - val_loss: 0.1884 - val_accuracy: 0.9736\n",
      "Epoch 39/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 0.1522 - val_accuracy: 0.9763\n",
      "Epoch 40/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.1590 - val_accuracy: 0.9772\n",
      "Epoch 41/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.1659 - val_accuracy: 0.9766\n",
      "Epoch 42/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.1507 - val_accuracy: 0.9771\n",
      "Epoch 43/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0256 - accuracy: 0.9944 - val_loss: 0.1633 - val_accuracy: 0.9759\n",
      "Epoch 44/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 0.1520 - val_accuracy: 0.9778\n",
      "Epoch 45/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.1509 - val_accuracy: 0.9770\n",
      "Epoch 46/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0220 - accuracy: 0.9952 - val_loss: 0.1765 - val_accuracy: 0.9759\n",
      "Epoch 47/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0214 - accuracy: 0.9947 - val_loss: 0.1622 - val_accuracy: 0.9769\n",
      "Epoch 48/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0202 - accuracy: 0.9952 - val_loss: 0.1683 - val_accuracy: 0.9773\n",
      "Epoch 49/50\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0254 - accuracy: 0.9945 - val_loss: 0.1522 - val_accuracy: 0.9766\n",
      "Epoch 50/50\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0197 - accuracy: 0.9955 - val_loss: 0.1571 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "## regardons le taux de succes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d_with_drop_more_epochs = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ici nous voyons que le resultat est beaucoup plus interessant mais on peut diminuer les valeur de nos hyperparametres pour avoir une meilleur perforamence\n",
    "## Dans notre cas nous allons un peu reduire le nombre d'epochs\n",
    "\n",
    "\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " \n",
    " Dense(hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden2_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden3_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden4_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(hidden5_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    "    \n",
    " Dense(output_num_units,activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "268/268 [==============================] - 5s 15ms/step - loss: 1.0047 - accuracy: 0.6600 - val_loss: 0.2816 - val_accuracy: 0.9238\n",
      "Epoch 2/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.3409 - accuracy: 0.9116 - val_loss: 0.1839 - val_accuracy: 0.9515\n",
      "Epoch 3/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.2346 - accuracy: 0.9426 - val_loss: 0.1729 - val_accuracy: 0.9557\n",
      "Epoch 4/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1856 - accuracy: 0.9558 - val_loss: 0.1391 - val_accuracy: 0.9651\n",
      "Epoch 5/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1570 - accuracy: 0.9625 - val_loss: 0.1384 - val_accuracy: 0.9673\n",
      "Epoch 6/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1340 - accuracy: 0.9690 - val_loss: 0.1344 - val_accuracy: 0.9687\n",
      "Epoch 7/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1218 - accuracy: 0.9713 - val_loss: 0.1475 - val_accuracy: 0.9667\n",
      "Epoch 8/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1045 - accuracy: 0.9753 - val_loss: 0.1294 - val_accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.1005 - accuracy: 0.9759 - val_loss: 0.1289 - val_accuracy: 0.9712\n",
      "Epoch 10/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0835 - accuracy: 0.9794 - val_loss: 0.1422 - val_accuracy: 0.9698\n",
      "Epoch 11/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0809 - accuracy: 0.9805 - val_loss: 0.1239 - val_accuracy: 0.9739\n",
      "Epoch 12/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0776 - accuracy: 0.9814 - val_loss: 0.1330 - val_accuracy: 0.9729\n",
      "Epoch 13/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.1507 - val_accuracy: 0.9717\n",
      "Epoch 14/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0640 - accuracy: 0.9851 - val_loss: 0.1352 - val_accuracy: 0.9720\n",
      "Epoch 15/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0569 - accuracy: 0.9863 - val_loss: 0.1357 - val_accuracy: 0.9741\n",
      "Epoch 16/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0591 - accuracy: 0.9862 - val_loss: 0.1363 - val_accuracy: 0.9737\n",
      "Epoch 17/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0573 - accuracy: 0.9860 - val_loss: 0.1345 - val_accuracy: 0.9738\n",
      "Epoch 18/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0520 - accuracy: 0.9876 - val_loss: 0.1543 - val_accuracy: 0.9703\n",
      "Epoch 19/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0500 - accuracy: 0.9882 - val_loss: 0.1429 - val_accuracy: 0.9757\n",
      "Epoch 20/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0485 - accuracy: 0.9886 - val_loss: 0.1325 - val_accuracy: 0.9748\n",
      "Epoch 21/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0438 - accuracy: 0.9901 - val_loss: 0.1376 - val_accuracy: 0.9756\n",
      "Epoch 22/25\n",
      "268/268 [==============================] - 4s 15ms/step - loss: 0.0395 - accuracy: 0.9902 - val_loss: 0.1321 - val_accuracy: 0.9761\n",
      "Epoch 23/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0416 - accuracy: 0.9898 - val_loss: 0.1255 - val_accuracy: 0.9771\n",
      "Epoch 24/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0404 - accuracy: 0.9903 - val_loss: 0.1388 - val_accuracy: 0.9751\n",
      "Epoch 25/25\n",
      "268/268 [==============================] - 4s 16ms/step - loss: 0.0421 - accuracy: 0.9900 - val_loss: 0.1458 - val_accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "## regardons le taux de succes\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_deep_n_wide = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## passons a l'evaluation de ce dernier modele qui semble le meilleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(test_x),axis=1)## on predit les classe de notre jeux de test\n",
    "img_name = rng.choice(test.filename) ## on fait un choix aleatoire pour notre jeux de text par nom de fichier\n",
    "filepath = os.path.join(data_dir, 'Images', 'test', img_name)\n",
    "img = imread(filepath)\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "print(\"Prediction is: \", pred[test_index])\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
